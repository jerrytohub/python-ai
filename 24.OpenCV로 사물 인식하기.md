# YOLO
* YOLO는 You Only Look Once의 약자로 최첨단 실시간 객체인식 시스템입니다.
* 이미지가 주어지면 배경과 사물을 구분하고 어떤 사물인지 인식합니다.
* YOLO는 R-CNN계열의 방식처럼 이미지를 여러 장 나눠서 여러 번 분석하지 않고 한 번에 분석합니다.
* YOLO를 사용해서 OpenCV로 사물인식을 할 수 있습니다.

## YOLO 사용해보기
* https://github.com/ultralytics/yolov5 사이트에 들어갑니다.
* Code > Download ZIP을 클릭해서 다운로드 받습니다.
* C드라이브에 yolo 폴더를 만들어서 압축을 풉니다.
* VSCODE를 실행합니다.
* ```pip install -r requirements.txt```로 requirements.txt에 있는 모듈을 설치합니다.
    * 여러 모듈을 설치하기 때문에 시간이 걸립니다.
* detect.py가 사물을 인식하는 프로그램입니다.
    * detect.py에 있는 ```python detect.py --weights yolov5s.pt --source 0``` 코드를 실행합니다.
        * yolov5s.pt를 다운로드 받아서 사물인식을 합니다.
        * pt는 pre-trained의 약자로 학습된 모델 파일입니다.
        * 0이면 웹캠입니다.
* 사진 하나를 폴더에 옮겨서 확인해봅니다.
    * ```python detect.py --weights yolov5s.pt --source 파일이름``` 
    * runs\detect 폴더 아래에 결과가 저장됩니다.

# 코랩에서 학습하기
* 구글 코랩에서 학습을 하겠습니다.
* 학습을 시키기 위해서 데이터가 필요합니다.
* https://public.roboflow.com// 에서 데이터를 다운로드 받습니다.
* Object Detection에서 Synthetic Fruit Dataset를 선택합니다.
    * 과일 데이터입니다.
    * 구글 계정으로 로그인합니다.
    * 파일 형식은 YOLO v5 PyTorch를 선택합니다.
    * show download code를 선택합니다.
    * Terminal을 선택합니다.
        * ```curl -L "https://public.roboflow.com/ds/sStLoPzD0P?key=gtR4lPpiEY" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip```
* 코랩에서 GPU를 선택합니다.
* !를 먼저 입력하고 복사한 명령어를 붙여넣습니다. !curl ~~
* content 폴더에 train과 valid 폴더가 생깁니다.
* data.yaml에 names에 과일 이름이 나옵니다.
* ```!git clone https://github.com/ultralytics/yolov5.git```으로 다운로드 받습니다.
* ```%cd yolov5```로 경로를 이동합니다.
    * ```!pwd```로 경로를 확인합니다.
* ```!pip install -r requirements.txt```로 필요한 모듈을 설치합니다.
* ```!python train.py --img 416 --batch 16 --epochs 50 --data /content/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name fruit_yolov5s_results```로 학습을 합니다.
    * --img : 학습할 사진의 크기
    * --batch : 전체 데이터를 얼마만큼 쪼개서 학습할 것인지 정하기
    * --epochs : 전체 데이터를 몇 회 반복학습할 것인지 정하기
    * --data : 데이터셋의 경로정보를 가지고 있는 yaml 파일 정하기
    * --cfg : 학습에 사용할 모델 파일 정하기
    * --cof : 확률
    * --weights : 학습에 사용할 모델 파일 정하기
    * --name : 학습결과를 저장할 폴더 이름 정하기
* 학습하는데 시간이 많이 걸립니다.(1시간 넘게 걸립니다.)
    * --epochs는 10으로 바꿔서 테스트를 하고 50으로 바꿔서 확인해봅니다.
    * 학습결과 best.pt라는 파일이 만들어집니다.
        * runs/train/fruit_yolov5s_results/weights에 만들어집니다.

## YOLO 학습 모델 다운로드 링크
* https://drive.google.com/file/d/1g7xFcx0VdOi7bgS-O-V5BCn1g9HwKPWz/view?usp=sharing

## 테스트
* 과일 사진을 코랩에 업로드 합니다.
* ```python detect.py --weights yolov5s.pt --source 0``` 명령어를 복사해서 사용합니다.
* ```python detect.py --weights 학습파일경로 --source 사진경로``` 명령어로 확인해봅니다.
* ```python detect.py --weights ./runs/train/fruit_yolov5s_results/weights/best.pt --source /remon.jpg``` 명령어로 확인해봅니다.
   * 코랩에서는 !를 붙입니다.    
* 확률을 정할 수 있습니다.
    * ```python detect.py --weights ./runs/train/fruit_yolov5s_results/weights/best.pt --cof 0.5 --source /lemon.jpg```
    * 코랩에서는 !를 붙입니다. 
* 사물인식 결과가 저장되는 경로에 들어가서 확인합니다.
* best.pt 파일을 다운로드 받고 yolov5s.pt 대신에 사용해봅니다.
    * 웹캠으로 과일 사진을 촬영해서 테스트합니다.
    * ```python detect.py --weights best.pt --source 0```

## 사진이나 영상으로 테스트하기
* 학습한 모델로 테스트를 하고 그 결과를 스크린샷으로 저장하세요.
