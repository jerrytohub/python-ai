{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb19ec3b",
   "metadata": {},
   "source": [
    "# 동영상에서 얼굴 인식하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6d1ab",
   "metadata": {},
   "source": [
    "## 동영상 읽기\n",
    "* VideoCapture 객체를 만들어서 동영상을 읽습니다.\n",
    "    * 번호는 컴퓨터에 연결된 장치번호입니다.\n",
    "        * 0부터 입력해봅니다.\n",
    "    * isOpened()로 동영상 파일을 열렸는지, 동영상을 잘 촬영하고 있는지 확인합니다.\n",
    "    * read()로 읽으면 2가지 값을 반환합니다.\n",
    "        * 첫번째는 성공여부\n",
    "        * 두번째는 읽은 프레임\n",
    "* 카메라가 열리는데 시간이 좀 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while capture.isOpened(): # 동영상이 열렸다면 - 동영상을 잘 촬영하고 있다면\n",
    "    ret, frame = capture.read() # ret : 성공여부 / frame : 프레임\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27: # 27은 esc키다.\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우 반전을 하고 gray 스케일로 바꿉니다.\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while capture.isOpened(): # 동영상이 열렸다면 - 동영상을 잘 촬영하고 있다면\n",
    "    ret, frame = capture.read() # ret : 성공여부 / frame : 프레임\n",
    "    frame = cv2.flip(frame, 1) # 좌우 반전합니다.\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # gray 스케일로 바꿉니다.\n",
    "    cv2.imshow(\"VideoFrame\", grayframe)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27: # 27은 esc키다.\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "932c9e29",
   "metadata": {},
   "source": [
    "## 얼굴 인식하기\n",
    "* https://github.com/opencv/opencv/tree/master/data/haarcascades 에서 데이터를 다운로드 받습니다.\n",
    "    * haarcascade_frontalface_default.xml을 다운로드 받습니다.\n",
    "* haarcascade_frontalface_default.xml 파일을 C:\\opencv에 다운로드 받습니다.\n",
    "    * 주피터 노트북 파일과 같은 폴더에 놓아도 됩니다.\n",
    "* CascadeClassifier(캐스케이드 분류기)로 얼굴을 인식합니다.\n",
    "    * CascadeClassifier에 입력한 데이터로 영상을 분석해서 찾아줍니다.\n",
    "* equalizeHist : 히스토그램 평활화\n",
    "    * 밝기 값이 몰려 있어서 어둡기만 한 영상 또는 밝기만 한 영상을 좀 더 선명한 영상으로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier() # 캐스케이드 객체를 만듭니다.\n",
    "face_cascade.load(r'C:\\opencv\\haarcascade_frontalface_default.xml') # 데이터를 입력합니다.\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1) # 좌우 반전합니다.\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # gray 스케일로 바꿉니다.\n",
    "    grayframe = cv2.equalizeHist(grayframe) # 영상을 더 잘 분석할 수 있도록 평활화를 합니다.\n",
    "    # 회색으로 좀 더 얼굴 인식이 잘 되도록 합니다.\n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (30, 30))\n",
    "    # 인식을 하면 x, y, w, h 값을 확인할 수 있습니다.\n",
    "    # 얼굴을 여러 개 인식할 수 있습니다.\n",
    "    for (x,y,w,h) in faces: \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "    cv2.imshow(\"Face\", frame)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27: # 27은 esc키다.\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb41a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load(r'C:\\opencv\\haarcascade_frontalface_default.xml')\n",
    "font = cv2.FONT_HERSHEY_DUPLEX # 폰트를 정합니다.\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1) \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    grayframe = cv2.equalizeHist(grayframe)     \n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.1, 3, 0, (30, 30))  \n",
    "    for (x,y,w,h) in faces: \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "        # 인식한 얼굴 위에 face라는 글씨를 씁니다.\n",
    "        cv2.putText(frame, \"face\", (x, y-10), font, 0.5, (255,0,0))\n",
    "    cv2.imshow(\"Face\", frame)\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27: \n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3274277",
   "metadata": {},
   "source": [
    "# 눈을 인식하기\n",
    "* https://github.com/opencv/opencv/tree/master/data/haarcascades 에서 데이터를 다운로드 받습니다.\n",
    "    * haarcascade_eye.xml을 다운로드 받습니다.\n",
    "* 눈을 인식해서 사각형으로 표시해주고 eye라고 글씨를 인식한 사각형 위에 씁니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
