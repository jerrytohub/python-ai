{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24d6310",
   "metadata": {},
   "source": [
    "# Mediapipe\n",
    "* Mediapipe는 구글에서 개발한 오픈 소스 플랫폼 프레임워크으로 얼굴인식, 포즈, 객체감지, 모션트레킹 등 다양한 형태의 기능과 모델을 제공합니다.\n",
    "* Mediapipe 사이트 > Solutions > See Demos에서 다양한 예제를 확인할 수 있습니다.\n",
    "* Mediapipe는 현재 파이썬 3.8 ~ 3.11 버전에서 작동합니다.\n",
    "    * https://developers.google.com/mediapipe/solutions/setup_python\n",
    "    * 나중에 사용할 수 있는 파이썬 버전은 바뀔 수 있습니다.\n",
    "* ```pip install mediapipe```로 설치합니다. \n",
    "    * user 관련 문제로 설치가 잘 안 되면 ```pip install --user mediapipe```로 설치합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d00ea",
   "metadata": {},
   "source": [
    "## mediapipe 사용해보기\n",
    "* 손가락을 인식하는 프로그램을 실행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b04394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    "    ) as hands:\n",
    "\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame)\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:                            \n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        cv2.imshow(\"Finger\", frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeab7e4",
   "metadata": {},
   "source": [
    "## 얼굴 인식하기\n",
    "* mediapipe 사이트에 다양한 예제 코드가 있습니다.\n",
    "* 얼굴을 촬영해서 오른쪽 눈, 왼쪽 눈, 코 끝부분, 입 중심, 오른쪽 귀, 왼쪽 귀 위치를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766e70e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "                       \n",
    "# 얼굴을 찾고, 찾은 얼굴에 표시를 해주기 위한 변수를 정의합니다.\n",
    "# 얼굴 검출을 위해서 face_detection 모듈을 사용합니다.\n",
    "mp_face_detection = mp.solutions.face_detection \n",
    "# 얼굴의 특징을 그리기 위해서 drawing_utils 모듈을 사용합니다.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "\n",
    "# mediapipe 사용방법에 맞게 설정합니다.\n",
    "# model_selection = 0은 카메라와 가까운 것을 인식합니다.\n",
    "# model_selection = 1은 카메라와 먼 것을 인식합니다.\n",
    "# min_detection_confidence=0.7는 70% 확신한다면 얼굴로 본다는 뜻입니다.\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.7) as face_detection:\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "        if not ret: # 읽지 못했다면 \n",
    "            continue             \n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(frame)\n",
    "       \n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)        \n",
    "        if results.detections:\n",
    "            # 6개 특징 \n",
    "            # 오른쪽 눈, 왼쪽 눈, 코 끝부분, 입 중심, 오른쪽 귀, 왼쪽 귀 위치가 점을 표시됩니다.\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(frame, detection)  \n",
    "                #print(detection)\n",
    "        cv2.imshow('MediaPipe Face Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06810a",
   "metadata": {},
   "source": [
    "* print(detection)으로 어떤 내용인지 확인합니다.\n",
    "* 촬영을 하고 얼굴을 인식하면 조금 있다가 ESC키를 누릅니다.\n",
    "* 6개의 relative_keypoints가 있습니다.\n",
    "    * 오른쪽 눈, 왼쪽 눈, 코 끝부분, 입 중심, 오른쪽 귀, 왼쪽 귀 좌푯값입니다.\n",
    "    * 이 좌푯값을 사용해서 얼굴 필터를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "                       \n",
    "mp_face_detection = mp.solutions.face_detection \n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.7) as face_detection:\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "        if not ret: \n",
    "            continue             \n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(frame)\n",
    "       \n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)        \n",
    "        if results.detections:\n",
    "            # 6개 특징 \n",
    "            # 오른쪽 눈, 왼쪽 눈, 코 끝부분, 입 중심, 오른쪽 귀, 왼쪽 귀 위치가 점을 표시됩니다.\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(frame, detection)  \n",
    "                # 위치를 나타내는 것을 keypoints 리스트에 저장합니다.\n",
    "                keypoints = detection.location_data.relative_keypoints\n",
    "                # keypoints[0]은 오른쪽 눈입니다.\n",
    "                # keypoints[0].x는 x좌표이고 keypoints[0].y는 y좌표입니다.\n",
    "                nose = keypoints[2]\n",
    "                # frame의 크기로 계산합니다.\n",
    "                # frame.shape은 높이, 너비, 채널 값입니다.\n",
    "                h, w, c = frame.shape  \n",
    "                # 튜플로 다시 저장합니다.\n",
    "                nose = (int(nose.x * w), int(nose.y * h))\n",
    "                # 원을 그립니다.\n",
    "                cv2.circle(frame, nose, 50, (0,0,255), 10, cv2.LINE_AA)\n",
    "        cv2.imshow('MediaPipe Face Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "            \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ed8f5",
   "metadata": {},
   "source": [
    "# 얼굴 필터 만들기\n",
    "* 양쪽 눈에 그림을 그려주는 프로그램을 만들어보세요.\n",
    "    * 사각형이나 원을 그려줍니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
